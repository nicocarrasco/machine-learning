{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert real value in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_type(df: pd.DataFrame, types: pd.DataFrame):\n",
    "  for idx, column in enumerate(df.columns):\n",
    "    if (types[idx] == 'r'):\n",
    "      df[column] = pd.to_numeric(df[column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import iris file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_file = pd.read_csv('iris.tmls')\n",
    "\n",
    "iris = pd.DataFrame(iris_file)\n",
    "\n",
    "# Extract row which inform on the type of features\n",
    "iris_types = iris.iloc[0]\n",
    "\n",
    "# Remove of the table the row which inform on the type of features\n",
    "iris = iris.drop(iris.index[0])\n",
    "\n",
    "# Convert real value columns into numeric values\n",
    "convert_type(iris, iris_types)\n",
    "\n",
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Wine file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_file = pd.read_csv('wine.tmls')\n",
    "\n",
    "wine = pd.DataFrame(wine_file)\n",
    "\n",
    "wine_types = wine.iloc[0]\n",
    "\n",
    "wine = wine.drop(wine.index[0])\n",
    "\n",
    "convert_type(wine, wine_types)\n",
    "\n",
    "wine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import adult file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_file = pd.read_csv('adult.tmls')\n",
    "\n",
    "adult = pd.DataFrame(adult_file)\n",
    "\n",
    "adult_types = adult.iloc[0]\n",
    "\n",
    "adult = adult.drop(adult.index[0])\n",
    "\n",
    "convert_type(adult, adult_types)\n",
    "\n",
    "adult.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Gini index to estimate disorder : Gini index is used instead of entropy because it gives similar results almost everytime for classifier and is less computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(data, classes: list):\n",
    "  data_len = len(data)\n",
    "  if (data_len == 0):\n",
    "    return 0\n",
    "  sum_classes = 0\n",
    "  for class_name in classes:\n",
    "    sum_classes += (data.count(class_name) / data_len)**2\n",
    "  return 1 - sum_classes\n",
    "\n",
    "# Estimate the disorder of the left and the right nodes depending on their relative size\n",
    "def split_gini_index(classes_splited, classes, dataset_size):\n",
    "  l_relative_size, r_relative_size = len(classes_splited[\"left\"]) / dataset_size, len(classes_splited[\"right\"]) / dataset_size\n",
    "  l_gini, r_gini = gini_index(classes_splited[\"left\"], classes) * l_relative_size, gini_index(classes_splited[\"right\"], classes) * r_relative_size\n",
    "  return l_gini + r_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split a dataset in two nodes by a certain feature and a certain value in order to have the less disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the separation values for each column/feature :\n",
    "# - mean of the feature for real-value column\n",
    "# - all the different nominal value for nominal column ()\n",
    "def get_col_values(dataset, col_size, dataset_size):\n",
    "  col_values = []\n",
    "  for col in range(col_size - 1):\n",
    "    col_values.append([])\n",
    "  for row in range(dataset_size):\n",
    "    for col in range(col_size - 1):\n",
    "      if ((not type(dataset[row][col]) is str) or (not dataset[row][col] in col_values[col])):\n",
    "        col_values[col].append(dataset[row][col])\n",
    "  for col in range(col_size - 1):\n",
    "    if not (type(col_values[col][0]) is str):\n",
    "      col_values[col] = [sum(col_values[col]) / len(col_values[col])]\n",
    "  return col_values\n",
    "\n",
    "# Split rows into 2 node depending the value of the row\n",
    "def split_dataset_in_two(dataset, val, col):\n",
    "  splited = {\"left\": [], \"right\": []}\n",
    "  if (type(val) is str):\n",
    "    for row in dataset:\n",
    "      if (row[col] != val):\n",
    "        splited[\"left\"].append(row)\n",
    "      else:\n",
    "        splited[\"right\"].append(row)\n",
    "  else:\n",
    "    for row in dataset:\n",
    "      if (row[col] < val):\n",
    "        splited[\"left\"].append(row)\n",
    "      else:\n",
    "        splited[\"right\"].append(row)\n",
    "  return splited\n",
    "\n",
    "# Find the split with the less disorder\n",
    "def find_best_split(dataset, col_size, classes):\n",
    "  b_gini = 1\n",
    "  dataset_size = len(dataset)\n",
    "  col_values = get_col_values(dataset=dataset, col_size=col_size, dataset_size=dataset_size)\n",
    "  for col in range(col_size - 1):\n",
    "    for col_val in col_values[col]:\n",
    "      splited = split_dataset_in_two(dataset, col_val, col)\n",
    "      classes_splited = {\"left\": [row[-1] for row in splited[\"left\"]],\n",
    "                          \"right\": [row[-1] for row in splited[\"right\"]]}\n",
    "      gini = split_gini_index(classes_splited, classes, dataset_size)\n",
    "      if (gini < b_gini):\n",
    "        b_gini = gini\n",
    "  return col, col_val, splited\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cell:\n",
    "  col = 0\n",
    "  value = ''\n",
    "  dataset = []\n",
    "  left = {}\n",
    "  right = {}\n",
    "  end = False\n",
    "\n",
    "# Return classes of the dataset\n",
    "def get_classes(dataset):\n",
    "  classes = []\n",
    "  for i in range(len(dataset)):\n",
    "    if not (dataset[i][-1] in classes):\n",
    "      classes.append(dataset[i][-1])\n",
    "  classes.sort()\n",
    "  return classes\n",
    "\n",
    "# Fill node with his left and right child, the feature and the value used to split\n",
    "def update_cell(node, col, value, splited):\n",
    "  node.col = col\n",
    "  node.value = value\n",
    "  node.left = cell()\n",
    "  node.right = cell()\n",
    "  node.left.dataset, node.right.dataset = splited[\"left\"], splited[\"right\"]\n",
    "\n",
    "# Creating the leaf of the tree and save the most represented class as the value class of the leaf\n",
    "def end_node(node: cell, lst):\n",
    "  node.end = True\n",
    "  node.value = max(set(lst), key=lst.count)\n",
    "\n",
    "# Build decision tree node by node by splitting the node in two thanks to gini index in each iteration\n",
    "def build_decision_tree(node: cell, col_size, classes, depth, max_depth, min_records):\n",
    "  # End tree when max_depth is met\n",
    "  if (depth == max_depth):\n",
    "    end_node(node, [row[-1] for row in node.dataset])\n",
    "    return\n",
    "  col, value, splited = find_best_split(node.dataset, col_size, classes)\n",
    "  update_cell(node, col, value, splited)\n",
    "  if (len(node.left.dataset) > min_records):\n",
    "    build_decision_tree(node.left, col_size, classes, depth + 1, max_depth, min_records)\n",
    "  # End tree when not enough data in dataset\n",
    "  else:\n",
    "    end_node(node.left, [row[-1] for row in node.dataset])\n",
    "  if (len(node.right.dataset) > min_records):\n",
    "    build_decision_tree(node.right, col_size, classes, depth + 1, max_depth, min_records)\n",
    "  # End tree when not enough data in dataset\n",
    "  else:\n",
    "    end_node(node.right, [row[-1] for row in node.dataset])\n",
    "  # Free dataset to free memory with useless information\n",
    "  node.dataset = []\n",
    "\n",
    "# Predict the class of a row by searching in the tree depending its features values\n",
    "def predict_class(node: cell, row):\n",
    "  if (node.end == True):\n",
    "    return node.value\n",
    "  if (type(node.value) is str):\n",
    "    if (row[node.col] != node.value):\n",
    "      return predict_class(node.left, row)\n",
    "    else:\n",
    "      return predict_class(node.right, row)\n",
    "  else:\n",
    "    if (row[node.col] < node.value):\n",
    "      return predict_class(node.left, row)\n",
    "    else:\n",
    "      return predict_class(node.right, row)\n",
    "\n",
    "# Create decison tree with train and predict class from test row thanks to this tree\n",
    "def decision_tree_learner(train, test, max_depth, min_records):\n",
    "  predictions = []\n",
    "  col_size = len(train[0])\n",
    "  classes = get_classes(train + test)\n",
    "  root = cell()\n",
    "  root.dataset = train\n",
    "  col, value, splited = find_best_split(train, col_size, classes)\n",
    "  update_cell(root, col, value, splited)\n",
    "  build_decision_tree(root, col_size, classes, 1, max_depth, min_records)\n",
    "  for row in test:\n",
    "    predictions.append(predict_class(root, row))\n",
    "  return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "# Split randomly dataset in K folds\n",
    "def split_dataset(dataset: pd.DataFrame, k_folds: int):\n",
    "  fold_size = int(len(dataset.index) / k_folds)\n",
    "  folds = []\n",
    "  for _ in range(k_folds):\n",
    "    fold = []\n",
    "    for _ in range(fold_size):\n",
    "      idx = randrange(len(dataset.index))\n",
    "      fold.append(dataset.iloc[idx].to_list())\n",
    "      dataset = dataset.drop(dataset.index[idx])\n",
    "    folds.append(fold)\n",
    "  return folds\n",
    "\n",
    "def get_accuracy(results: list, predictions: list):\n",
    "  accuracy = 0\n",
    "  for i in range(len(predictions)):\n",
    "    if (predictions[i] == results[i]):\n",
    "      accuracy += 1\n",
    "  accuracy = accuracy / len(predictions)\n",
    "  return accuracy\n",
    "\n",
    "def cross_validation(dataset: pd.DataFrame, k_folds: int, max_depth=5, min_records=10):\n",
    "  dataset_copy = dataset.copy()\n",
    "  folds = split_dataset(dataset_copy, k_folds)\n",
    "  accuracy_array = []\n",
    "  for idx in range(k_folds):\n",
    "    results = [row[-1] for row in folds[idx]]\n",
    "    train =  [row for fold in folds[:idx] for row in fold] + [row for fold in folds[idx + 1 :] for row in fold]\n",
    "    predictions = decision_tree_learner(train=train, test=folds[idx], max_depth=max_depth, min_records=min_records)\n",
    "    accuracy = get_accuracy(results, predictions)\n",
    "    accuracy_array.append(accuracy)\n",
    "  return accuracy_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris decision learner accuracy (accuracy is significantly better when we have only two target class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation(iris, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wine decision learner accuracy (accuracy is significantly better when we have only two target class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation(wine, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adult decision learner accuracy (take approximately 2min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation(adult, 10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f1e4f854c3b11040df263fcfa2d7a054c8290a68abb1fec0decd7fbc057637c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
